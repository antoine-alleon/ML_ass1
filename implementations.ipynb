{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6 basic method implementations as described above in step 2: We want you to implement and use the methods \n",
    "#we have seen in class and in the labs. You will need to provide working implementations of the functions in Table 1. \n",
    "#If you have not finished them during the labs, you should start by implementing the first ones to have a working \n",
    "#toolbox before diving in the dataset.\n",
    "\n",
    "#Return type: Note that all functions should return: (w, loss), which is the last weight vector of the method, \n",
    "#and the corresponding loss value (cost function). Note that while in previous labs you might have kept track of \n",
    "#all encountered w for iterative methods, here we only want the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_MSE(y, tx, w):\n",
    "    MSE=((np.linalg.norm(y-(np.dot(tx,w))))**2)/(2*len(y))\n",
    "    \n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx, n_max):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    xx=np.delete(tx,0,1) #save x vector\n",
    "    for i in range(n_max-2):\n",
    "        np.append(tx,np.power(xx,i+2)) #add powers of x to tx\n",
    "    w_opt=np.linalg.solve(np.matmul(np.transpose(tx),tx),np.dot(np.transpose(tx),y)) #compute weights\n",
    "    mse=compute_MSE(y,tx,w_opt) #compute error\n",
    "    \n",
    "    return mse, w_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, n_max, lambda_):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    lambda_=lambda_/(2*np.shape(y))\n",
    "    xx=np.delete(tx,0,1) #save x vector\n",
    "    for i in range(n_max-2):\n",
    "        np.append(tx,np.power(xx,i+2)) #add powers of x to tx\n",
    "    w_opt=np.linalg.solve(np.matmul(np.transpose(tx),tx)+lambda_*np.identity(np.shape(y)),np.dot(np.transpose(tx),y)) #compute weights\n",
    "    mse=compute_MSE(y,tx,w_opt) #compute error\n",
    "    \n",
    "    return mse,w_opt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
